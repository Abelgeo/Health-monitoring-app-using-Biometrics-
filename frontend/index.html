<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Emotion-Aware Health Monitoring</title>
  <script src="https://cdn.jsdelivr.net/npm/axios@1.4.0/dist/axios.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/Chart.js/4.4.4/chart.umd.min.js"></script>
  <script src="https://cdn.tailwindcss.com"></script>
  <style>
    body {
      background: linear-gradient(135deg, #1a1a2e, #16213e);
      color: #e0e7ff;
      font-family: 'Arial', sans-serif;
    }
    .neon-text {
      text-shadow: 0 0 5px #0ff, 0 0 10px #0ff, 0 0 20px #f0f, 0 0 30px #f0f;
    }
    .neon-border {
      box-shadow: 0 0 10px #0ff, 0 0 20px #f0f, inset 0 0 10px #0ff;
    }
    canvas, video {
      border: 2px solid #0ff;
      border-radius: 8px;
      box-shadow: 0 0 15px #0ff, 0 0 25px #f0f;
    }
    .health-bar {
      height: 20px;
      background: #333;
      border-radius: 10px;
      overflow: hidden;
    }
    .health-fill {
      height: 100%;
      transition: width 0.5s;
    }
    .good { background: #0f0; }
    .medium { background: #ff0; }
    .bad { background: #f00; }
    .recording-indicator {
      display: inline-block;
      width: 12px;
      height: 12px;
      background: #f00;
      border-radius: 50%;
      margin-left: 8px;
      animation: pulse 1s infinite;
    }
    @keyframes pulse {
      0%, 100% { opacity: 1; }
      50% { opacity: 0.5; }
    }
  </style>
</head>
<body class="min-h-screen flex flex-col items-center p-4">
  <h1 class="text-4xl font-bold neon-text mb-6">Emotion-Aware Health Monitoring</h1>
  <div class="grid grid-cols-1 md:grid-cols-2 gap-6 w-full max-w-6xl">
    <div class="flex flex-col items-center">
      <video id="video" width="640" height="480" autoplay muted class="neon-border"></video>
      <canvas id="canvas" width="640" height="480" class="hidden"></canvas>
      <button id="manualTest" class="mt-2 bg-cyan-500 text-black px-4 py-2 rounded neon-text hover:bg-pink-500">
        Manual Test (Voice + Image)<span id="recordingDot"></span>
      </button>
      <p id="recordingStatus" class="text-sm text-yellow-300 mt-2"></p>
    </div>
    <div class="flex flex-col">
      <canvas id="healthChart" width="640" height="400" class="neon-border"></canvas>
    </div>
  </div>
  <div class="mt-6 w-full max-w-6xl">
    <h2 class="text-2xl font-semibold neon-text">Health Insights</h2>
    <div id="insights" class="mt-4 bg-gray-800 bg-opacity-50 p-4 rounded-lg neon-border">
      <p><strong>Stress Level:</strong> <span id="stress">N/A</span></p>
      <p><strong>HRV (ms):</strong> <span id="hrv">N/A</span></p>
      <p><strong>Sentiment Score:</strong> <span id="sentiment">N/A</span></p>
      <p><strong>Gait Status:</strong> <span id="gait">N/A</span></p>
      <p><strong>Overall Health Score:</strong> <span id="healthScore">N/A</span></p>
      <div class="health-bar mt-1">
        <div id="healthFill" class="health-fill" style="width: 0%;"></div>
      </div>
    </div>
    <h2 class="text-2xl font-semibold neon-text mt-6">Voice Transcript</h2>
    <p id="transcript" class="bg-gray-800 bg-opacity-50 p-4 rounded-lg neon-border mt-2 text-sm">No transcript yet.</p>
    <h2 class="text-2xl font-semibold neon-text mt-6">Recommendations</h2>
    <ul id="recommendations" class="list-disc pl-5 mt-2 text-lg"></ul>
    <h2 class="text-2xl font-semibold neon-text mt-6">Tips</h2>
    <ul id="tips" class="list-disc pl-5 mt-2 text-lg">
      <li>Click "Manual Test" to record voice (3 seconds) + capture image.</li>
      <li>Speak clearly for better sentiment analysis.</li>
      <li>Frown for higher stress; smile for lower.</li>
      <li>Walk irregularly in front of camera for gait anomaly detection.</li>
    </ul>
  </div>

  <script>
    const video = document.getElementById('video');
    const canvas = document.getElementById('canvas');
    const ctx = canvas.getContext('2d');
    const chartCanvas = document.getElementById('healthChart');
    const chartCtx = chartCanvas.getContext('2d');
    const manualBtn = document.getElementById('manualTest');
    const recordingStatus = document.getElementById('recordingStatus');
    const recordingDot = document.getElementById('recordingDot');
    let chart;
    let useChartJS = typeof Chart !== 'undefined';
    let mediaRecorder;
    let audioChunks = [];
    let audioData = '';
    let isRecording = false;
    let mediaStream;

    // Request mic + camera
    navigator.mediaDevices.getUserMedia({ video: true, audio: { echoCancellation: true, noiseSuppression: true } })
      .then(stream => {
        video.srcObject = stream;
        mediaStream = stream;
        
        mediaRecorder = new MediaRecorder(stream, {
          mimeType: MediaRecorder.isTypeSupported('audio/webm;codecs=opus') ? 'audio/webm;codecs=opus' : 'audio/wav',
          audioBitsPerSecond: 128000
        });
        
        mediaRecorder.ondataavailable = e => audioChunks.push(e.data);
        
        mediaRecorder.onstop = () => {
          const audioBlob = new Blob(audioChunks, { type: 'audio/webm' });
          const reader = new FileReader();
          reader.onload = () => {
            audioData = reader.result;
            isRecording = false;
            recordingDot.innerHTML = '';
            recordingStatus.textContent = 'Audio recorded! Processing...';
          };
          reader.onerror = () => {
            recordingStatus.textContent = 'Error reading audio';
          };
          reader.readAsDataURL(audioBlob);
          audioChunks = [];
        };
      })
      .catch(err => recordingStatus.textContent = 'Microphone/Camera access denied');

    let stressData = [];
    let hrvData = [];
    let sentimentData = [];
    let labels = [];

    function initChart() {
      if (useChartJS) {
        chart = new Chart(chartCtx, {
          type: 'line',
          data: {
            labels: labels,
            datasets: [
              { label: 'Stress Level', data: stressData, borderColor: '#0ff', backgroundColor: 'rgba(0, 255, 255, 0.2)', tension: 0.4, pointBackgroundColor: '#f0f' },
              { label: 'HRV (ms)', data: hrvData, borderColor: '#f0f', backgroundColor: 'rgba(255, 0, 255, 0.2)', tension: 0.4, pointBackgroundColor: '#0ff' },
              { label: 'Sentiment Score', data: sentimentData, borderColor: '#0f0', backgroundColor: 'rgba(0, 255, 0, 0.2)', tension: 0.4, pointBackgroundColor: '#00f' }
            ]
          },
          options: {
            responsive: true,
            scales: { y: { beginAtZero: true, max: 100 } },
            plugins: { legend: { labels: { color: '#e0e7ff' } } }
          }
        });
        return true;
      }
      chartCtx.fillStyle = '#1a1a2e';
      chartCtx.fillRect(0, 0, chartCanvas.width, chartCanvas.height);
      return false;
    }

    function updateChart() {
      if (useChartJS && chart) {
        chart.data.labels = labels;
        chart.data.datasets[0].data = stressData;
        chart.data.datasets[1].data = hrvData.map(v => v > 100 ? 100 : v);
        chart.data.datasets[2].data = sentimentData;
        chart.update();
        return;
      }
      // Fallback draw
      const width = chartCanvas.width;
      const height = chartCanvas.height;
      chartCtx.clearRect(0, 0, width, height);
      chartCtx.fillStyle = '#1a1a2e';
      chartCtx.fillRect(0, 0, width, height);

      // Axes (always draw)
      chartCtx.strokeStyle = '#e0e7ff';
      chartCtx.lineWidth = 1;
      chartCtx.beginPath();
      chartCtx.moveTo(50, height - 50);
      chartCtx.lineTo(width - 50, height - 50);
      chartCtx.lineTo(width - 50, 50);
      chartCtx.stroke();

      if (stressData.length > 1) {
        const stepX = (width - 100) / (stressData.length - 1);
        const scaleY = (height - 100) / 100;

        // Stress (cyan)
        chartCtx.strokeStyle = '#0ff';
        chartCtx.lineWidth = 2;
        chartCtx.beginPath();
        stressData.forEach((val, i) => {
          const x = 50 + i * stepX;
          const y = height - 50 - val * scaleY;
          if (i === 0) chartCtx.moveTo(x, y);
          else chartCtx.lineTo(x, y);
        });
        chartCtx.stroke();

        // HRV (magenta)
        chartCtx.strokeStyle = '#f0f';
        chartCtx.lineWidth = 2;
        chartCtx.beginPath();
        hrvData.forEach((val, i) => {
          const capped = val > 100 ? 100 : val;
          const x = 50 + i * stepX;
          const y = height - 50 - capped * scaleY;
          if (i === 0) chartCtx.moveTo(x, y);
          else chartCtx.lineTo(x, y);
        });
        chartCtx.stroke();

        // Sentiment (green)
        chartCtx.strokeStyle = '#0f0';
        chartCtx.lineWidth = 2;
        chartCtx.beginPath();
        sentimentData.forEach((val, i) => {
          const x = 50 + i * stepX;
          const y = height - 50 - val * scaleY;
          if (i === 0) chartCtx.moveTo(x, y);
          else chartCtx.lineTo(x, y);
        });
        chartCtx.stroke();

        // Points
        stressData.forEach((val, i) => {
          const x = 50 + i * stepX;
          const y = height - 50 - val * scaleY;
          chartCtx.beginPath();
          chartCtx.arc(x, y, 3, 0, 2 * Math.PI);
          chartCtx.fillStyle = '#f0f';
          chartCtx.fill();
        });
        hrvData.forEach((val, i) => {
          const capped = val > 100 ? 100 : val;
          const x = 50 + i * stepX;
          const y = height - 50 - capped * scaleY;
          chartCtx.beginPath();
          chartCtx.arc(x, y, 3, 0, 2 * Math.PI);
          chartCtx.fillStyle = '#0ff';
          chartCtx.fill();
        });
        sentimentData.forEach((val, i) => {
          const x = 50 + i * stepX;
          const y = height - 50 - val * scaleY;
          chartCtx.beginPath();
          chartCtx.arc(x, y, 3, 0, 2 * Math.PI);
          chartCtx.fillStyle = '#00f';
          chartCtx.fill();
        });
      } else {
        // Empty state text
        chartCtx.fillStyle = '#e0e7ff';
        chartCtx.font = '16px Arial';
        chartCtx.textAlign = 'center';
        chartCtx.fillText('No data yetâ€”wait for analysis', width / 2, height / 2);
      }

      // Labels (always)
      chartCtx.fillStyle = '#0ff';
      chartCtx.font = '12px Arial';
      chartCtx.textAlign = 'left';
      chartCtx.fillText('Stress', width - 100, height - 70);
      chartCtx.fillStyle = '#f0f';
      chartCtx.fillText('HRV', width - 100, height - 55);
      chartCtx.fillStyle = '#0f0';
      chartCtx.fillText('Sentiment', width - 100, height - 40);
      chartCtx.textAlign = 'left';
    }

    function sendAnalysisRequest(imageData, audio) {
      console.log("Sending request with audio length:", audio ? audio.length : 0);
      
      axios.post('http://localhost:5000/analyze', { 
        image: imageData, 
        audio: audio || '' 
      })
        .then(response => {
          const data = response.data;
          console.log("Response:", data);
          
          if (!data.emotions || !data.hrv || !data.gait || !data.voice) {
            console.error("Missing data fields in response");
            return;
          }

          // Update insights
          document.getElementById('stress').textContent = (data.emotions.stress * 100).toFixed(1) + '%';
          document.getElementById('hrv').textContent = data.hrv.value.toFixed(1);
          document.getElementById('sentiment').textContent = (data.voice.stress * 100).toFixed(1) + '%';
          document.getElementById('gait').textContent = data.gait.anomaly ? 'Anomaly Detected' : 'Normal';
          document.getElementById('healthScore').textContent = data.health_score;
          
          const fill = document.getElementById('healthFill');
          fill.style.width = data.health_score + '%';
          fill.className = 'health-fill ' + (data.health_score > 70 ? 'good' : data.health_score > 40 ? 'medium' : 'bad');

          // Transcript
          document.getElementById('transcript').textContent = data.voice.transcript || 'No transcript';

          // Recommendations
          const recList = document.getElementById('recommendations');
          recList.innerHTML = '';
          data.recommendations.forEach(rec => {
            const li = document.createElement('li');
            li.textContent = rec;
            li.className = 'text-cyan-300';
            recList.appendChild(li);
          });

          // Chart data
          stressData.push(data.emotions.stress * 100);
          hrvData.push(data.hrv.value);
          sentimentData.push(data.voice.stress * 100);
          labels.push(new Date().toLocaleTimeString().slice(-8));
          if (stressData.length > 10) {
            stressData.shift();
            hrvData.shift();
            sentimentData.shift();
            labels.shift();
          }
          updateChart();  // Always call
          
          recordingStatus.textContent = 'Analysis complete!';
        })
        .catch(err => {
          console.error('API error:', err);
          recordingStatus.textContent = 'Error: ' + (err.response?.data?.error || err.message);
        });
    }

    function analyzeFrame(isManual = false) {
      if (!video.videoWidth) {
        setTimeout(() => analyzeFrame(isManual), 1000);
        return;
      }

      // Capture image
      ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
      const imageData = canvas.toDataURL('image/jpeg');

      if (isManual) {
        // Start recording audio
        if (mediaRecorder && mediaRecorder.state !== 'recording') {
          audioChunks = [];
          audioData = ''; // Reset
          mediaRecorder.start();
          isRecording = true;
          recordingDot.innerHTML = '<span class="recording-indicator"></span>';
          recordingStatus.textContent = 'Recording audio... (3 seconds)';
          console.log("Recording started");
          
          // Stop after 3 seconds and send
          setTimeout(() => {
            if (mediaRecorder && mediaRecorder.state === 'recording') {
              mediaRecorder.stop();
              console.log("Recording stopped, waiting for FileReader...");
              
              // Wait for FileReader to complete (with timeout)
              const checkInterval = setInterval(() => {
                if (!isRecording || audioData.length > 0) {
                  clearInterval(checkInterval);
                  console.log("Sending analysis with audio");
                  sendAnalysisRequest(imageData, audioData);
                }
              }, 100);
              
              // Timeout after 2 seconds
              setTimeout(() => {
                clearInterval(checkInterval);
                console.log("FileReader timeout, sending anyway");
                sendAnalysisRequest(imageData, audioData);
              }, 2000);
            }
          }, 3000);
        }
      } else {
        // Auto mode (no audio)
        sendAnalysisRequest(imageData, '');
      }
    }

    // Events
    manualBtn.addEventListener('click', () => analyzeFrame(true));

    // Start (auto for image only)
    initChart();
    setTimeout(() => {
      setInterval(() => analyzeFrame(false), 5000);
      analyzeFrame(false);
    }, 2000);
  </script>
</body>
</html>